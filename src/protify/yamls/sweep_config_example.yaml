method: bayes
metric:
  name: eval_loss
  goal: minimize

parameters:
  # Learning rate optimization
  lr:
    distribution: log_uniform
    min: 1e-5
    max: 1e-2
  
  # Weight decay for regularization
  weight_decay:
    distribution: log_uniform
    min: 1e-6
    max: 1e-1
  
  # Batch size options
  probe_batch_size:
    values: [16, 32, 64, 128]
  
  # Dropout for regularization
  dropout:
    distribution: uniform
    min: 0.0
    max: 0.5
  
  # Model architecture parameters
  hidden_dim:
    values: [512, 1024, 2048, 4096]
  
  n_layers:
    values: [1, 2, 3, 4]
  
  classifier_dim:
    values: [512, 1024, 2048, 4096]
  
  # Transformer-specific parameters (if using transformer probe)
  transformer_dropout:
    distribution: uniform
    min: 0.0
    max: 0.3
  
  classifier_dropout:
    distribution: uniform
    min: 0.0
    max: 0.5
  
  n_heads:
    values: [2, 4, 8, 16]

# Alternative search methods you can use:
# method: grid  # for exhaustive grid search
# method: random  # for random search

# Alternative metrics you can optimize for:
# metric:
#   name: eval_accuracy  # for classification tasks
#   goal: maximize
#
# metric:
#   name: eval_f1  # for F1 score
#   goal: maximize
#
# metric:
#   name: eval_mse  # for regression tasks  
#   goal: minimize 